{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from notebook_modules.database import Database\n",
    "from notebook_modules.half import Half\n",
    "from notebook_modules.distribution import aggregate\n",
    "from notebook_modules.lists import save_db, load_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_from_fs = True\n",
    "\n",
    "if not load_from_fs:\n",
    "    db = Database()\n",
    "    assert db.client, \"No database client available!\"\n",
    "    stackoverflow = db.client[\"stackoverflow\"]\n",
    "    tags = stackoverflow[\"tags\"]\n",
    "    posts = stackoverflow[\"posts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_period = Half.make_half(2019, 2)\n",
    "halves = Half.make_halves(2008, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_from_fs:\n",
    "    full_tags = load_db(topic=\"tsa\", name=\"full-tags\")\n",
    "else:\n",
    "    full_tags = aggregate(posts, current_period, full=True)\n",
    "    save_db(full_tags, topic=\"tsa\", name=\"full-tags\")\n",
    "full_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregate_time_periods(periods, unit=\"half\"):\n",
    "    time_periods = []\n",
    "\n",
    "    for period in tqdm(periods, unit=unit, ascii=True):\n",
    "        tags_from_posts = aggregate(posts, period)\n",
    "        if tags_from_posts.empty:\n",
    "            time_periods.append({\"_date\": period.end})\n",
    "        else:\n",
    "            keys = tags_from_posts.tag.values\n",
    "            values = tags_from_posts.frequency.values\n",
    "            time_periods.append({\"_date\": period.end, **dict(zip(keys, values))})\n",
    "\n",
    "    return time_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if load_from_fs:\n",
    "    time_series = load_db(topic=\"tsa\", name=\"time-series\")\n",
    "else:\n",
    "    time_periods = aggregate_time_periods(halves, unit=\"half\")\n",
    "    time_series = pd.DataFrame(time_periods, columns=[\"_date\", *full_tags.tag.values])\n",
    "    time_series.fillna(0, inplace=True)\n",
    "    save_db(time_series, topic=\"tsa\", name=\"time-series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series._date = pd.to_datetime(time_series._date)\n",
    "time_series.set_index(\"_date\", inplace=True)\n",
    "time_series.index = pd.DatetimeIndex(time_series.index.values, freq=time_series.index.inferred_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_data = time_series.T\n",
    "time_series_data.index.name = \"tag\"\n",
    "time_series_data_full = time_series_data\n",
    "\n",
    "# the top 18 % (n=10205) of all tags cover 95,61 % of all used tags in questions\n",
    "time_series_data = time_series_data.head(int(len(time_series_data) * 0.18))\n",
    "\n",
    "# remove all tags that don't occur in the second last time period\n",
    "time_series_data_full = time_series_data_full[time_series_data_full[time_series_data_full.columns[-2]] > 0]\n",
    "time_series_data = time_series_data[time_series_data[time_series_data.columns[-2]] > 0]\n",
    "time_series_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_threshold = 0.05\n",
    "# {\"decaying\": 1, \"undecaying\": 0}\n",
    "classify = lambda d: 1 if d >= class_threshold else 0\n",
    "\n",
    "def generate_classes(data):\n",
    "    classes = []\n",
    "\n",
    "    for row in data.itertuples():\n",
    "        old_value = row[-2]\n",
    "        new_value = row[-1]\n",
    "        decrease = (old_value - new_value) / old_value\n",
    "        given_class = classify(decrease)\n",
    "        classes.append({\"tag\": row[0], \"class\": given_class})\n",
    "\n",
    "    time_series_classes = pd.DataFrame(classes)\n",
    "    time_series_classes.set_index(\"tag\", inplace=True)\n",
    "    return time_series_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_classes_full = generate_classes(time_series_data_full)\n",
    "time_series_classes = generate_classes(time_series_data)\n",
    "time_series_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    rec = true_positives / (possible_positives + K.epsilon())\n",
    "    return rec\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    pre = true_positives / (predicted_positives + K.epsilon())\n",
    "    return pre\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    pre = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    f1 = 2 * ((pre * rec) / (pre + rec + K.epsilon()))\n",
    "    return f1\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    true_positives = K.sum(K.cast(y_true * y_pred, \"float\"), axis=0)\n",
    "    true_negatives = K.sum(K.cast((1 - y_true) * (1 - y_pred), \"float\"), axis=0)\n",
    "    false_positives = K.sum(K.cast((1 - y_true) * y_pred, \"float\"), axis=0)\n",
    "    false_negatives = K.sum(K.cast(y_true * (1 - y_pred), \"float\"), axis=0)\n",
    "\n",
    "    pre = true_positives / (true_positives + false_positives + K.epsilon())\n",
    "    rec = true_positives / (true_positives + false_negatives + K.epsilon())\n",
    "\n",
    "    f1 = 2 * pre * rec / (pre + rec + K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(time_series_data, time_series_classes, test_size=0.1)\n",
    "n_features = x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# create model, add dense layers one by one specifying activation function\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=len(n_features), activation=\"relu\")) # input layer requires input_dim param\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\")) # sigmoid instead of relu for final probability between 0 and 1\n",
    "\n",
    "# compile the model, adam gradient descent (optimized)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", f1_score, precision, recall])\n",
    "\n",
    "# call the function to fit to the data (training the network)\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate(x_test, y_test)\n",
    "dict(zip(model.metrics_names, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate(time_series_data_full, time_series_classes_full)\n",
    "dict(zip(model.metrics_names, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}