{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from notebook_modules.database import Database\n",
    "from notebook_modules.half import Half\n",
    "from notebook_modules.distribution import aggregate\n",
    "from notebook_modules.lists import save_db, load_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_from_fs = True\n",
    "\n",
    "if not load_from_fs:\n",
    "    db = Database()\n",
    "    assert db.client, \"No database client available!\"\n",
    "    stackoverflow = db.client[\"stackoverflow\"]\n",
    "    tags = stackoverflow[\"tags\"]\n",
    "    posts = stackoverflow[\"posts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_period = Half.make_half(2019, 2)\n",
    "halves = Half.make_halves(2008, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_from_fs:\n",
    "    full_tags = load_db(topic=\"tsa\", name=\"full-tags\")\n",
    "else:\n",
    "    full_tags = aggregate(posts, current_period, full=True)\n",
    "    save_db(full_tags, topic=\"tsa\", name=\"full-tags\")\n",
    "full_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregate_time_periods(periods, unit=\"half\"):\n",
    "    time_periods = []\n",
    "\n",
    "    for period in tqdm(periods, unit=unit, ascii=True):\n",
    "        tags_from_posts = aggregate(posts, period)\n",
    "        if tags_from_posts.empty:\n",
    "            time_periods.append({\"_date\": period.end})\n",
    "        else:\n",
    "            keys = tags_from_posts.tag.values\n",
    "            values = tags_from_posts.frequency.values\n",
    "            time_periods.append({\"_date\": period.end, **dict(zip(keys, values))})\n",
    "\n",
    "    return time_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if load_from_fs:\n",
    "    time_series = load_db(topic=\"tsa\", name=\"time-series\")\n",
    "else:\n",
    "    time_periods = aggregate_time_periods(halves, unit=\"half\")\n",
    "    time_series = pd.DataFrame(time_periods, columns=[\"_date\", *full_tags.tag.values])\n",
    "    time_series.fillna(0, inplace=True)\n",
    "    save_db(time_series, topic=\"tsa\", name=\"time-series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series._date = pd.to_datetime(time_series._date)\n",
    "time_series.set_index(\"_date\", inplace=True)\n",
    "time_series.index = pd.DatetimeIndex(time_series.index.values, freq=time_series.index.inferred_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select tags that appeared over a certain threshold\n",
    "time_series = time_series.loc[:, time_series.sum(axis=\"rows\") >= 280.0]\n",
    "train, test = time_series.iloc[:23, :], time_series.iloc[23:, :]\n",
    "time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_current = time_series[time_series.columns[0]]\n",
    "train_current = train[train.columns[0]]\n",
    "test_current = test[test.columns[0]]\n",
    "\n",
    "train_data = train_current.values.reshape(-1, 1)\n",
    "test_data = test_current.values.reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data)\n",
    "\n",
    "train_scaled = scaler.transform(train_data)\n",
    "test_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 1\n",
    "n_features = 1\n",
    "n_units = 20\n",
    "\n",
    "generator = TimeseriesGenerator(train_scaled, train_scaled, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=n_units, input_shape=(n_input, n_features)))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(units=n_features))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "model.fit_generator(generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, show_shapes=True, show_layer_names=True, to_file=\"output/models/model-tsa.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}